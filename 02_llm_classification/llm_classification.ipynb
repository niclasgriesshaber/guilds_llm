{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import time\n",
    "import nltk\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from openai.error import RateLimitError\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Key\n",
    "You need your own OpenAI key to run the LLM-based sentence classification task. You can create your own API key here: https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to regulations_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/niclasgriesshaber/Desktop/guilds-llm/02_llm_classification\n",
      "Path to regulations_dataset.csv: /Users/niclasgriesshaber/Desktop/guilds-llm/datasets/llm_classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Getting path of current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current directory: {current_directory}\")\n",
    "\n",
    "# Path to regulations_dataset\n",
    "regulations_dataset_path = os.path.normpath(os.path.join(current_directory, '..', 'datasets', 'regulations_dataset.csv'))\n",
    "print(f\"Path to regulations_dataset.csv: {regulations_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regulations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(regulations_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...  \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...  \n",
       "2  1.— Que cualquiera persona de cualquiera calid...  \n",
       "3  Primeramente que al principio de cada un año s...  \n",
       "4  Primeramente, que en cada un año por principio...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text from LLM digitization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the OCR text provided by the large language model\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove line breaks\n",
    "    text_no_line_breaks = text.replace('\\n', ' ')\n",
    "\n",
    "    # Remove Arabic numeral patterns followed by a period\n",
    "    text_no_arabic_numerals = re.sub(r'\\b\\d+\\.\\s*', '', text_no_line_breaks)\n",
    "\n",
    "    # Use a regular expression to split on periods that are not part of \"etc.\" or similar abbreviations\n",
    "    sentences = re.split(r'(?<!\\betc)\\.\\s+(?=[A-Z])', text_no_arabic_numerals)\n",
    "\n",
    "    # Filter sentences with less than 4 words\n",
    "    cleaned_sentences = [sentence.strip() for sentence in sentences if len(sentence.split()) >= 4]\n",
    "    cleaned_text = '. '.join(cleaned_sentences)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create the new column 'cleaned_text'\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "      <td>Primeramente, que las mantas ordinarias se han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>—Primeramente, antes todas cosas, todos los pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>— Que cualquiera persona de cualquiera calidad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \\\n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...   \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...   \n",
       "2  1.— Que cualquiera persona de cualquiera calid...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Primeramente, que las mantas ordinarias se han...  \n",
       "1  —Primeramente, antes todas cosas, todos los pa...  \n",
       "2  — Que cualquiera persona de cualquiera calidad...  \n",
       "3  Primeramente que al principio de cada un año s...  \n",
       "4  Primeramente, que en cada un año por principio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the cleaned text into sentences\n",
    "df['sentences'] = df['cleaned_text'].apply(nltk.sent_tokenize)\n",
    "\n",
    "# Count the number of sentences in the ordinance\n",
    "df['sentence_count'] = df['sentences'].apply(lambda x: len(x))\n",
    "\n",
    "# Initialize the column 'classification_count' with NaN\n",
    "df['classification_count'] = np.nan\n",
    "df['classification_count'] = df['classification_count'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of total sentences in the regulations dataset\n",
    "df['sentence_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>classification_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "      <td>Primeramente, que las mantas ordinarias se han...</td>\n",
       "      <td>[Primeramente, que las mantas ordinarias se ha...</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>—Primeramente, antes todas cosas, todos los pa...</td>\n",
       "      <td>[—Primeramente, antes todas cosas, todos los p...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>— Que cualquiera persona de cualquiera calidad...</td>\n",
       "      <td>[— Que cualquiera persona de cualquiera calida...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>[Primeramente que al principio de cada un año ...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>[Primeramente, que en cada un año por principi...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \\\n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...   \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...   \n",
       "2  1.— Que cualquiera persona de cualquiera calid...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Primeramente, que las mantas ordinarias se han...   \n",
       "1  —Primeramente, antes todas cosas, todos los pa...   \n",
       "2  — Que cualquiera persona de cualquiera calidad...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                           sentences  sentence_count  \\\n",
       "0  [Primeramente, que las mantas ordinarias se ha...              40   \n",
       "1  [—Primeramente, antes todas cosas, todos los p...               5   \n",
       "2  [— Que cualquiera persona de cualquiera calida...               5   \n",
       "3  [Primeramente que al principio de cada un año ...               9   \n",
       "4  [Primeramente, que en cada un año por principi...              10   \n",
       "\n",
       "  classification_count  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 Multi-Category Classification Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task prompt to instruct GPT-4 to classify the sentence\n",
    "task_prompt = \"\"\"Clasifica la siguiente oración en español según las categorías a continuación: \n",
    "0: La oración menciona alguna forma de discriminación, por ejemplo, excluyendo a personas específicas, como negros, mulatos o indios del gremio, o de ser promovidos o que no pueden abrir su propia tienda. \n",
    "1: La oración menciona alguna forma de capital humano, como educación, aprendices, aprendizajes o exámenes de oficio dentro del gremio. \n",
    "2: La oración menciona la calidad del producto, quizás detallando el proceso de fabricación. \n",
    "3: La oración menciona cualquier cosa relacionada con los mercados económicos, posiblemente mencionando precios, suministro u otros conceptos de mercado similares. \n",
    "4: La oración menciona alguna forma de castigo, multas o autoridades que hacen cumplir las ordenanzas. \n",
    "5: La oración se refiere a alguna forma de religión, cofradías o hermandades. \n",
    "6: La oración no encaja en ninguna de las categorías anteriores. \n",
    "ALWAYS use the following format: 34 or 015. NEVER use commas (,), line breaks (\\n), or whitespaces ( ) in your response.\n",
    "If a sentence belongs to one category, only return a single number.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the LLM-based sentence classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature parameter is set to 0 for deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send a sentence with a task prompt to the OpenAI API\n",
    "def classify_sentence(task_prompt, text):\n",
    "    \"\"\"\n",
    "    Classifies a given sentence `text` based on a set of categories described in `task_prompt`.\n",
    "    \n",
    "    Args:\n",
    "    - task_prompt (str): A detailed description of the categories for classification.\n",
    "    - text (str): The sentence to classify.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The classification result.\n",
    "    \"\"\"\n",
    "    \n",
    "    message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"{task_prompt}\\nOración para clasificar: {text}\"\n",
    "    }\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[message],\n",
    "        temperature=0.0, # Set to 0.0 to get deterministic results\n",
    "        seed = 42,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying every sentence of an ordinance using GPT-4\n",
    "def classify_and_count(task_prompt, sentences, delay_time=5):\n",
    "    classifications = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        print(f'Analysing new sentence {i}')\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                classification = classify_sentence(task_prompt, sentence)\n",
    "                classifications.append(classification)\n",
    "                break  # Exit the loop if the function call was successful\n",
    "            except Exception as e:\n",
    "                print(f'Error occurred: {e}. Retrying at:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                time.sleep(delay_time)\n",
    "                print('Retrying now at:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    counter = Counter(classifications)\n",
    "    return dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the whole dataset for LLM-based sentence classification task\n",
    "def process_dataframe(df, task_prompt, delay_time=5):\n",
    "    length = len(df)\n",
    "    for i in range(length):\n",
    "        print(f'Starting new ordinance: {i}')\n",
    "        try:\n",
    "            current_sentences = df.loc[i]['sentences']\n",
    "            my_dict = classify_and_count(task_prompt, current_sentences, delay_time)\n",
    "            df.at[i, 'classification_count'] = my_dict\n",
    "            print('Dictionary added to dataframe:', my_dict)\n",
    "            \n",
    "        except RateLimitError as e:\n",
    "            print(f\"Rate limit reached. Waiting for {e.retry_after}ms.\")\n",
    "            time.sleep(e.retry_after / 1000)  # Convert ms to seconds.\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Skipping sentence at index {i}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run LLM-based sentence classification task using GPT-4\n",
    "This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new ordinance: 0\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Dictionary added to dataframe: {'4': 11, '2': 17, '14': 5, '24': 3, '04': 1, '3': 1, '1': 1, '34': 1}\n",
      "Starting new ordinance: 1\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Dictionary added to dataframe: {'1': 1, '34': 1, '3': 1, '4': 2}\n",
      "Starting new ordinance: 2\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Dictionary added to dataframe: {'24': 3, '4': 2}\n",
      "Starting new ordinance: 3\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Dictionary added to dataframe: {'14': 3, '1': 4, '134': 1, '04': 1}\n",
      "Starting new ordinance: 4\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Dictionary added to dataframe: {'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15': 1, '01': 1}\n",
      "Starting new ordinance: 5\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Dictionary added to dataframe: {'4': 1, '2': 1, '1': 1, '14': 1}\n",
      "Starting new ordinance: 6\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Dictionary added to dataframe: {'2': 6, '3': 1, '4': 2}\n",
      "Starting new ordinance: 7\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Dictionary added to dataframe: {'4': 3, '1': 1, '2': 5, '14': 1, '04': 1}\n",
      "Starting new ordinance: 8\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Dictionary added to dataframe: {'1': 5, '04': 1, '14': 1, '4': 3, '2': 1, '6': 1}\n",
      "Starting new ordinance: 9\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Dictionary added to dataframe: {'14': 2, '1': 2, '2': 5}\n",
      "Starting new ordinance: 10\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Analysing new sentence 41\n",
      "Analysing new sentence 42\n",
      "Analysing new sentence 43\n",
      "Analysing new sentence 44\n",
      "Analysing new sentence 45\n",
      "Analysing new sentence 46\n",
      "Analysing new sentence 47\n",
      "Analysing new sentence 48\n",
      "Analysing new sentence 49\n",
      "Analysing new sentence 50\n",
      "Analysing new sentence 51\n",
      "Analysing new sentence 52\n",
      "Analysing new sentence 53\n",
      "Analysing new sentence 54\n",
      "Analysing new sentence 55\n",
      "Analysing new sentence 56\n",
      "Analysing new sentence 57\n",
      "Analysing new sentence 58\n",
      "Dictionary added to dataframe: {'1': 2, '14': 4, '4': 9, '2': 36, '24': 2, '3': 2, '6': 2, '014': 1, '0': 1}\n",
      "Starting new ordinance: 11\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Dictionary added to dataframe: {'14': 2, '24': 1, '2': 1, '04': 1}\n",
      "Starting new ordinance: 12\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Dictionary added to dataframe: {'4': 6, '234': 1}\n",
      "Starting new ordinance: 13\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Dictionary added to dataframe: {'234': 1, '2': 2, '24': 1, '04': 1}\n",
      "Starting new ordinance: 14\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Dictionary added to dataframe: {'15': 1, '4': 4, '14': 1, '5': 1, '3': 1}\n",
      "Starting new ordinance: 15\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Analysing new sentence 41\n",
      "Analysing new sentence 42\n",
      "Analysing new sentence 43\n",
      "Analysing new sentence 44\n",
      "Analysing new sentence 45\n",
      "Analysing new sentence 46\n",
      "Analysing new sentence 47\n",
      "Analysing new sentence 48\n",
      "Analysing new sentence 49\n",
      "Analysing new sentence 50\n",
      "Analysing new sentence 51\n",
      "Dictionary added to dataframe: {'5': 2, '4': 28, '1': 3, '14': 5, '24': 2, '2': 4, '6': 2, '3': 3, '04': 2, '34': 1}\n",
      "Starting new ordinance: 16\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Dictionary added to dataframe: {'14': 2, '24': 5, '04': 1, '1': 3, '4': 3, '2': 2, '3': 1}\n",
      "Starting new ordinance: 17\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Dictionary added to dataframe: {'1': 2, '14': 4, '4': 5, '2': 5, '24': 1, '145': 1}\n",
      "Starting new ordinance: 18\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Dictionary added to dataframe: {'4': 8, '14': 2, '3': 2, '2': 2, '24': 3, '0': 1}\n",
      "Starting new ordinance: 19\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Dictionary added to dataframe: {'1': 4, '14': 2, '4': 1, '24': 1, '2': 8, '5': 1, '6': 3}\n",
      "Starting new ordinance: 20\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Analysing new sentence 41\n",
      "Dictionary added to dataframe: {'5': 1, '3': 16, '0': 1, '4': 9, '1': 6, '34': 1, '24': 3, '2': 1, '6': 4}\n",
      "Starting new ordinance: 21\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Dictionary added to dataframe: {'0154': 1, '14': 1, '04': 1, '1': 1, '4': 2, '3': 1, '6': 1}\n",
      "Starting new ordinance: 22\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Dictionary added to dataframe: {'3': 5, '2': 4, '4': 1, '23': 1}\n",
      "Starting new ordinance: 23\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Dictionary added to dataframe: {'3': 1, '0': 1, '4': 1, '1': 3, '6': 1}\n",
      "Starting new ordinance: 24\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Dictionary added to dataframe: {'14': 1, '4': 5, '2': 1, '24': 1}\n",
      "Starting new ordinance: 25\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Dictionary added to dataframe: {'5': 1, '4': 5, '3': 7, '6': 2, '14': 1}\n",
      "Starting new ordinance: 26\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Dictionary added to dataframe: {'1': 8, '6': 3, '145': 1, '2': 3, '14': 1, '4': 6, '24': 1, '3': 1}\n",
      "Starting new ordinance: 27\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Dictionary added to dataframe: {'1': 1, '3': 2, '6': 1, '4': 7, '2': 1}\n",
      "Starting new ordinance: 28\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Dictionary added to dataframe: {'145': 1, '14': 3, '1': 1, '2': 2, '042': 2, '24': 4, '4': 5, '3': 1, '2 4': 1, '6': 2}\n",
      "Starting new ordinance: 29\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Dictionary added to dataframe: {'5': 1, '1': 3, '24': 1, '4': 2, '2': 1, '34': 1, '14': 1}\n",
      "Starting new ordinance: 30\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Dictionary added to dataframe: {'5': 1, '1': 16, '15': 1, '14': 2, '2': 4, '134': 1, '4': 12, '6': 1, '3': 1}\n",
      "Starting new ordinance: 31\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Analysing new sentence 41\n",
      "Analysing new sentence 42\n",
      "Analysing new sentence 43\n",
      "Analysing new sentence 44\n",
      "Dictionary added to dataframe: {'1': 3, '14': 3, '4': 25, '0': 1, '3': 2, '2': 4, '6': 3, '1345': 1, '24': 2, '34': 1}\n",
      "Starting new ordinance: 32\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Dictionary added to dataframe: {'1': 3, '2': 3, '4': 2, '3': 2, '14': 1}\n",
      "Starting new ordinance: 33\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Dictionary added to dataframe: {'1': 3, '2': 8, '12': 1, '3': 1, '4': 2}\n",
      "Starting new ordinance: 34\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Dictionary added to dataframe: {'1': 1, '3': 7, '2 4': 1, '4': 11, '34': 1, '6': 2, '2': 1}\n",
      "Starting new ordinance: 35\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Dictionary added to dataframe: {'1': 7, '14': 1, '145': 1, '24': 1, '2': 4, '04': 1, '4': 2}\n",
      "Starting new ordinance: 36\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Dictionary added to dataframe: {'2': 5, '1': 2, '4': 4, '0': 1, '01': 1, '3': 1, '6': 1}\n",
      "Starting new ordinance: 37\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Dictionary added to dataframe: {'6': 2, '4': 4, '2': 1, '3': 2}\n",
      "Starting new ordinance: 38\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Dictionary added to dataframe: {'15': 1, '5': 3, '1': 3, '1254': 1, '4': 3, '14': 1, '24': 1, '3': 1, '134': 1, '34': 1}\n",
      "Starting new ordinance: 39\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Dictionary added to dataframe: {'5': 4, '1': 4, '6': 1, '14': 6, '4': 4, '04': 1}\n",
      "Starting new ordinance: 40\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Dictionary added to dataframe: {'1': 14, '4': 12, '15': 1, '12': 1, '2': 1, '14': 2, '134': 1, '24': 1, '3': 1, '34': 1, '6': 1}\n",
      "Starting new ordinance: 41\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Analysing new sentence 41\n",
      "Analysing new sentence 42\n",
      "Analysing new sentence 43\n",
      "Analysing new sentence 44\n",
      "Analysing new sentence 45\n",
      "Analysing new sentence 46\n",
      "Analysing new sentence 47\n",
      "Analysing new sentence 48\n",
      "Analysing new sentence 49\n",
      "Analysing new sentence 50\n",
      "Analysing new sentence 51\n",
      "Analysing new sentence 52\n",
      "Analysing new sentence 53\n",
      "Analysing new sentence 54\n",
      "Analysing new sentence 55\n",
      "Analysing new sentence 56\n",
      "Analysing new sentence 57\n",
      "Dictionary added to dataframe: {'4': 33, '6': 10, '1': 3, '3': 11, '14': 1}\n",
      "Starting new ordinance: 42\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Dictionary added to dataframe: {'14': 3, '1': 18, '0': 1, '01': 1}\n",
      "Starting new ordinance: 43\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Analysing new sentence 38\n",
      "Analysing new sentence 39\n",
      "Analysing new sentence 40\n",
      "Dictionary added to dataframe: {'1': 4, '6': 8, '4': 11, '5': 1, '15': 1, '14': 2, '145': 1, '2': 9, '24': 2, '24, 4, 5': 1, '245': 1}\n",
      "Starting new ordinance: 44\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Dictionary added to dataframe: {'1': 5, '4': 6, '0': 1, '6': 1, '14': 1}\n",
      "Starting new ordinance: 45\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Dictionary added to dataframe: {'4': 3, '1': 2, '3': 5, '2': 4, '0': 1, '6': 5}\n",
      "Starting new ordinance: 46\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Dictionary added to dataframe: {'14': 5, '04': 1, '1': 1, '4': 5, '24': 1, '6': 1}\n",
      "Starting new ordinance: 47\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Dictionary added to dataframe: {'4': 4, '14': 1, '04': 1}\n",
      "Starting new ordinance: 48\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Analysing new sentence 37\n",
      "Dictionary added to dataframe: {'1': 5, '4': 14, '05': 1, '0': 2, '14': 5, '04': 1, '2': 3, '6': 4, '3': 2, '134': 1}\n",
      "Starting new ordinance: 49\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Analysing new sentence 28\n",
      "Analysing new sentence 29\n",
      "Analysing new sentence 30\n",
      "Analysing new sentence 31\n",
      "Analysing new sentence 32\n",
      "Analysing new sentence 33\n",
      "Analysing new sentence 34\n",
      "Analysing new sentence 35\n",
      "Analysing new sentence 36\n",
      "Dictionary added to dataframe: {'5': 1, '4': 6, '1': 10, '14': 4, '2': 13, '04': 1, '24': 1, '3': 1}\n",
      "Starting new ordinance: 50\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Dictionary added to dataframe: {'1': 4, '6': 1, '5': 1, '2': 1, '0': 1, '4': 1}\n",
      "Starting new ordinance: 51\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Dictionary added to dataframe: {'2': 2, '3': 1, '4': 1}\n",
      "Starting new ordinance: 52\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Dictionary added to dataframe: {'1': 6, '4': 7, '45': 2, '14': 4, '04': 1, '5': 1, '2': 1}\n",
      "Starting new ordinance: 53\n",
      "Analysing new sentence 0\n",
      "Analysing new sentence 1\n",
      "Analysing new sentence 2\n",
      "Analysing new sentence 3\n",
      "Analysing new sentence 4\n",
      "Analysing new sentence 5\n",
      "Analysing new sentence 6\n",
      "Analysing new sentence 7\n",
      "Analysing new sentence 8\n",
      "Analysing new sentence 9\n",
      "Analysing new sentence 10\n",
      "Analysing new sentence 11\n",
      "Analysing new sentence 12\n",
      "Analysing new sentence 13\n",
      "Analysing new sentence 14\n",
      "Analysing new sentence 15\n",
      "Analysing new sentence 16\n",
      "Analysing new sentence 17\n",
      "Analysing new sentence 18\n",
      "Analysing new sentence 19\n",
      "Analysing new sentence 20\n",
      "Analysing new sentence 21\n",
      "Analysing new sentence 22\n",
      "Analysing new sentence 23\n",
      "Analysing new sentence 24\n",
      "Analysing new sentence 25\n",
      "Analysing new sentence 26\n",
      "Analysing new sentence 27\n",
      "Dictionary added to dataframe: {'1': 8, '4': 8, '14': 1, '24': 1, '2': 3, '014': 1, '6': 5, '3': 1}\n",
      "Finished processing dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Run LLM-based sentence classification task using GPT-4\n",
    "process_dataframe(df, task_prompt)\n",
    "print('Finished processing dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>classification_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "      <td>Primeramente, que las mantas ordinarias se han...</td>\n",
       "      <td>[Primeramente, que las mantas ordinarias se ha...</td>\n",
       "      <td>40</td>\n",
       "      <td>{'4': 11, '2': 17, '14': 5, '24': 3, '04': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>—Primeramente, antes todas cosas, todos los pa...</td>\n",
       "      <td>[—Primeramente, antes todas cosas, todos los p...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'1': 1, '34': 1, '3': 1, '4': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>— Que cualquiera persona de cualquiera calidad...</td>\n",
       "      <td>[— Que cualquiera persona de cualquiera calida...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'24': 3, '4': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>[Primeramente que al principio de cada un año ...</td>\n",
       "      <td>9</td>\n",
       "      <td>{'14': 3, '1': 4, '134': 1, '04': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>[Primeramente, que en cada un año por principi...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \\\n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...   \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...   \n",
       "2  1.— Que cualquiera persona de cualquiera calid...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Primeramente, que las mantas ordinarias se han...   \n",
       "1  —Primeramente, antes todas cosas, todos los pa...   \n",
       "2  — Que cualquiera persona de cualquiera calidad...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                           sentences  sentence_count  \\\n",
       "0  [Primeramente, que las mantas ordinarias se ha...              40   \n",
       "1  [—Primeramente, antes todas cosas, todos los p...               5   \n",
       "2  [— Que cualquiera persona de cualquiera calida...               5   \n",
       "3  [Primeramente que al principio de cada un año ...               9   \n",
       "4  [Primeramente, que en cada un año por principi...              10   \n",
       "\n",
       "                                classification_count  \n",
       "0  {'4': 11, '2': 17, '14': 5, '24': 3, '04': 1, ...  \n",
       "1                  {'1': 1, '34': 1, '3': 1, '4': 2}  \n",
       "2                                  {'24': 3, '4': 2}  \n",
       "3               {'14': 3, '1': 4, '134': 1, '04': 1}  \n",
       "4  {'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataset to check classification results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing of LLM-based sentence classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if every row contains a valid dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid dictionaries: 54\n"
     ]
    }
   ],
   "source": [
    "# Check if each entry is a dictionary\n",
    "is_dict = df['classification_count'].apply(lambda x: isinstance(x, dict))\n",
    "\n",
    "# There should be 54 valid dictionaries\n",
    "print(f'Number of valid dictionaries: {is_dict.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check unique characters in dictionary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['245', '34', '24, 4, 5', '1', '014', '6', '2', '042', '45', '05', '04', '12', '4', '1254', '0154', '23', '1345', '14', '3', '145', '234', '2 4', '15', '24', '134', '01', '5', '0']\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and 'classification_count' is the column with dictionaries\n",
    "unique_keys = set().union(*df['classification_count'].apply(lambda x: x.keys()))\n",
    "\n",
    "# Convert the set to a list if you need a list\n",
    "unique_keys_list = list(unique_keys)\n",
    "\n",
    "# Print the unique keys\n",
    "print(unique_keys_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove potential whitespaces from dictionary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove whitespaces from dictionary keys\n",
    "def remove_whitespace_from_keys(d):\n",
    "    return {k.replace(' ', ''): v for k, v in d.items()}\n",
    "\n",
    "# Apply the function to each dictionary in the 'classification_count' column\n",
    "df['classification_count'] = df['classification_count'].apply(remove_whitespace_from_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['245', '34', '1', '014', '6', '2', '042', '45', '05', '04', '12', '4', '1254', '0154', '23', '1345', '14', '3', '145', '234', '24,4,5', '15', '24', '134', '01', '5', '0']\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and 'classification_count' is the column with dictionaries\n",
    "unique_keys = set().union(*df['classification_count'].apply(lambda x: x.keys()))\n",
    "\n",
    "# Convert the set to a list if you need a list\n",
    "unique_keys_list = list(unique_keys)\n",
    "\n",
    "print(unique_keys_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform classification count to classification dictionary\n",
    "For example, disentangle \"04\" into \"0\" and \"4\" in a new classification dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the column 'classification_dict' with NaN\n",
    "df['classification_dict'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disentangle multi-classifications such as \"04\" into \"0\" and \"4\"\n",
    "def transform_dict(original_dict):\n",
    "    \n",
    "    # Initialize new dictionary\n",
    "    new_dict = {str(i): 0 for i in range(7)}  # Adjusted range to 0-7 for single-digit numbers\n",
    "    \n",
    "    # Ensure the original_dict is an actual dictionary\n",
    "    if isinstance(original_dict, str):\n",
    "        original_dict = ast.literal_eval(original_dict)\n",
    "    \n",
    "    # Count occurrences\n",
    "    for key, value in original_dict.items():\n",
    "        if len(key) > 1:  # If the key has more than one digit\n",
    "            numbers = list(key)  # Directly convert the string to a list of its characters\n",
    "        else:\n",
    "            numbers = [key]  # If it's a single digit, make it a list\n",
    "        for num in numbers:\n",
    "            num = num.strip()  # Remove any leading or trailing whitespace\n",
    "            if num in new_dict:  # Check if num is a valid key in new_dict\n",
    "                new_dict[num] += value\n",
    "            else:\n",
    "                print(f\"Unexpected number found in key: {num}\")  # For debugging\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'classification_count' is the column with dictionaries\n",
    "# Apply the transformation to each row in the 'classification_count' column\n",
    "df['classification_dict'] = df['classification_count'].apply(transform_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>classification_count</th>\n",
       "      <th>classification_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "      <td>Primeramente, que las mantas ordinarias se han...</td>\n",
       "      <td>['Primeramente, que las mantas ordinarias se h...</td>\n",
       "      <td>40</td>\n",
       "      <td>{'24': 1, '2': 19, '14': 7, '4': 9, '04': 1, '...</td>\n",
       "      <td>{'0': 1, '1': 7, '2': 20, '3': 2, '4': 19, '5'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>—Primeramente, antes todas cosas, todos los pa...</td>\n",
       "      <td>['—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'1': 1, '34': 1, '3': 1, '4': 2}</td>\n",
       "      <td>{'0': 0, '1': 1, '2': 0, '3': 2, '4': 3, '5': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>— Que cualquiera persona de cualquiera calidad...</td>\n",
       "      <td>['— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'24': 1, '4': 4}</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 1, '3': 0, '4': 5, '5': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>['Primeramente que al principio de cada un año...</td>\n",
       "      <td>9</td>\n",
       "      <td>{'14': 2, '1': 5, '2': 1, '04': 1}</td>\n",
       "      <td>{'0': 1, '1': 7, '2': 1, '3': 0, '4': 3, '5': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>['Primeramente, que en cada un año por princip...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...</td>\n",
       "      <td>{'0': 1, '1': 5, '2': 2, '3': 2, '4': 2, '5': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \\\n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...   \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...   \n",
       "2  1.— Que cualquiera persona de cualquiera calid...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Primeramente, que las mantas ordinarias se han...   \n",
       "1  —Primeramente, antes todas cosas, todos los pa...   \n",
       "2  — Que cualquiera persona de cualquiera calidad...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                           sentences  sentence_count  \\\n",
       "0  ['Primeramente, que las mantas ordinarias se h...              40   \n",
       "1  ['—Primeramente, antes todas cosas, todos los ...               5   \n",
       "2  ['— Que cualquiera persona de cualquiera calid...               5   \n",
       "3  ['Primeramente que al principio de cada un año...               9   \n",
       "4  ['Primeramente, que en cada un año por princip...              10   \n",
       "\n",
       "                                classification_count  \\\n",
       "0  {'24': 1, '2': 19, '14': 7, '4': 9, '04': 1, '...   \n",
       "1                  {'1': 1, '34': 1, '3': 1, '4': 2}   \n",
       "2                                  {'24': 1, '4': 4}   \n",
       "3                 {'14': 2, '1': 5, '2': 1, '04': 1}   \n",
       "4  {'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...   \n",
       "\n",
       "                                 classification_dict  \n",
       "0  {'0': 1, '1': 7, '2': 20, '3': 2, '4': 19, '5'...  \n",
       "1  {'0': 0, '1': 1, '2': 0, '3': 2, '4': 3, '5': ...  \n",
       "2  {'0': 0, '1': 0, '2': 1, '3': 0, '4': 5, '5': ...  \n",
       "3  {'0': 1, '1': 7, '2': 1, '3': 0, '4': 3, '5': ...  \n",
       "4  {'0': 1, '1': 5, '2': 2, '3': 2, '4': 2, '5': ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add century variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the century\n",
    "def determine_century(year):\n",
    "    if year == 1801:\n",
    "        return 18\n",
    "    return (year - 1) // 100 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the century for each year\n",
    "df['century'] = df['year'].apply(determine_century)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification count per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry Barriers: 43\n",
      "Human Capital: 294\n",
      "Product Quality: 226\n",
      "Markets: 96\n",
      "Punishment, Fines and Enforcement: 481\n",
      "Religion: 37\n",
      "Other: 67\n"
     ]
    }
   ],
   "source": [
    "# Initialize the totals dictionary\n",
    "totals = {str(i): 0 for i in range(7)}  \n",
    "\n",
    "# Calculate totals\n",
    "for i in range(len(df)):\n",
    "    for key in totals.keys():\n",
    "        totals[key] += df['classification_dict'][i].get(key, 0)\n",
    "\n",
    "# Define the labels\n",
    "labels = [\n",
    "    \"Entry Barriers\", \n",
    "    \"Human Capital\", \n",
    "    \"Product Quality\", \n",
    "    \"Markets\",\n",
    "    \"Punishment, Fines and Enforcement\", \n",
    "    \"Religion\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "# Print totals with labels\n",
    "for label, key in zip(labels, totals.keys()):\n",
    "    print(f\"{label}: {totals[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save llm classification results as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to save the classification results: /Users/niclasgriesshaber/Desktop/guilds-llm/datasets/llm_classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.normpath(os.path.join(current_directory, '..', 'datasets', 'llm_classification_results.csv'))\n",
    "print(f\"Path to save the classification results: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification results\n",
    "df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guilds-nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
