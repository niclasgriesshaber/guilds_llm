{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook transform the llm_classifications_results.csv into a sentence-level dataset to test for statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load llm_classification_results.csv\n",
    "We transform the classification_dict in this dataset into a sentence-level dataset for our probit regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/niclasgriesshaber/Desktop/guilds-llm/03_probit_regression\n",
      "Path to llm_classification_results.csv: /Users/niclasgriesshaber/Desktop/guilds-llm/datasets/llm_classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Getting path of current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current directory: {current_directory}\")\n",
    "\n",
    "# Path to llm_classification_results.csv\n",
    "llm_classification_results_path = os.path.normpath(os.path.join(current_directory, '..', 'datasets', 'llm_classification_results.csv'))\n",
    "print(f\"Path to llm_classification_results.csv: {llm_classification_results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regulations dataset for general analysis\n",
    "df = pd.read_csv(llm_classification_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>guild</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>classification_count</th>\n",
       "      <th>classification_dict</th>\n",
       "      <th>century</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1757</td>\n",
       "      <td>cotton-weavers</td>\n",
       "      <td>1.—Ordenanza primera. Primeramente, que las ma...</td>\n",
       "      <td>Primeramente, que las mantas ordinarias se han...</td>\n",
       "      <td>['Primeramente, que las mantas ordinarias se h...</td>\n",
       "      <td>40</td>\n",
       "      <td>{'24': 1, '2': 19, '14': 7, '4': 9, '04': 1, '...</td>\n",
       "      <td>{'0': 1, '1': 7, '2': 20, '3': 2, '4': 19, '5'...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1620</td>\n",
       "      <td>bakers</td>\n",
       "      <td>1.—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>—Primeramente, antes todas cosas, todos los pa...</td>\n",
       "      <td>['—Primeramente, antes todas cosas, todos los ...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'1': 1, '34': 1, '3': 1, '4': 2}</td>\n",
       "      <td>{'0': 0, '1': 1, '2': 0, '3': 2, '4': 3, '5': ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1592</td>\n",
       "      <td>cloth-makers</td>\n",
       "      <td>1.— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>— Que cualquiera persona de cualquiera calidad...</td>\n",
       "      <td>['— Que cualquiera persona de cualquiera calid...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'24': 1, '4': 4}</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 1, '3': 0, '4': 5, '5': ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1605</td>\n",
       "      <td>cloth-finishers</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>Primeramente que al principio de cada un año s...</td>\n",
       "      <td>['Primeramente que al principio de cada un año...</td>\n",
       "      <td>9</td>\n",
       "      <td>{'14': 2, '1': 5, '2': 1, '04': 1}</td>\n",
       "      <td>{'0': 1, '1': 7, '2': 1, '3': 0, '4': 3, '5': ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mexico</td>\n",
       "      <td>1706</td>\n",
       "      <td>tallow</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>Primeramente, que en cada un año por principio...</td>\n",
       "      <td>['Primeramente, que en cada un año por princip...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...</td>\n",
       "      <td>{'0': 1, '1': 5, '2': 2, '3': 2, '4': 2, '5': ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year            guild  \\\n",
       "0  mexico  1757   cotton-weavers   \n",
       "1  mexico  1620           bakers   \n",
       "2  mexico  1592     cloth-makers   \n",
       "3  mexico  1605  cloth-finishers   \n",
       "4  mexico  1706           tallow   \n",
       "\n",
       "                                                text  \\\n",
       "0  1.—Ordenanza primera. Primeramente, que las ma...   \n",
       "1  1.—Primeramente, antes todas cosas, todos los ...   \n",
       "2  1.— Que cualquiera persona de cualquiera calid...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Primeramente, que las mantas ordinarias se han...   \n",
       "1  —Primeramente, antes todas cosas, todos los pa...   \n",
       "2  — Que cualquiera persona de cualquiera calidad...   \n",
       "3  Primeramente que al principio de cada un año s...   \n",
       "4  Primeramente, que en cada un año por principio...   \n",
       "\n",
       "                                           sentences  sentence_count  \\\n",
       "0  ['Primeramente, que las mantas ordinarias se h...              40   \n",
       "1  ['—Primeramente, antes todas cosas, todos los ...               5   \n",
       "2  ['— Que cualquiera persona de cualquiera calid...               5   \n",
       "3  ['Primeramente que al principio de cada un año...               9   \n",
       "4  ['Primeramente, que en cada un año por princip...              10   \n",
       "\n",
       "                                classification_count  \\\n",
       "0  {'24': 1, '2': 19, '14': 7, '4': 9, '04': 1, '...   \n",
       "1                  {'1': 1, '34': 1, '3': 1, '4': 2}   \n",
       "2                                  {'24': 1, '4': 4}   \n",
       "3                 {'14': 2, '1': 5, '2': 1, '04': 1}   \n",
       "4  {'4': 1, '14': 1, '1': 2, '2': 2, '3': 2, '15'...   \n",
       "\n",
       "                                 classification_dict  century  \n",
       "0  {'0': 1, '1': 7, '2': 20, '3': 2, '4': 19, '5'...       18  \n",
       "1  {'0': 0, '1': 1, '2': 0, '3': 2, '4': 3, '5': ...       17  \n",
       "2  {'0': 0, '1': 0, '2': 1, '3': 0, '4': 5, '5': ...       16  \n",
       "3  {'0': 1, '1': 7, '2': 1, '3': 0, '4': 3, '5': ...       17  \n",
       "4  {'0': 1, '1': 5, '2': 2, '3': 2, '4': 2, '5': ...       18  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert string into dictionary\n",
    "Saving the dataframes as csv has the side-effect that dictionaries and lists are saved as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample ensure_dict function from the previous example\n",
    "def ensure_dict(variable):\n",
    "    # Check if the variable is a string\n",
    "    if isinstance(variable, str):\n",
    "        try:\n",
    "            # Attempt to convert the string to a dictionary\n",
    "            return ast.literal_eval(variable)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # If conversion fails, return the original string\n",
    "            return variable\n",
    "    else:\n",
    "        # If the variable isn't a string, return it unchanged\n",
    "        return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'classification_count' column\n",
    "df['classification_dict'] = df['classification_dict'].apply(ensure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build sentence-level dataset\n",
    "Unit of analysis: The sentence. This allows us to perform a probit regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df, category_key, category_label):\n",
    "    # Add a new column to count the occurrences of the specified category\n",
    "    df[f'{category_label.lower().replace(\" \", \"_\")}_counts'] = df['classification_dict'].apply(lambda x: x.get(category_key, 0))\n",
    "    \n",
    "    # Initialize an empty list to store the rows for the new DataFrame\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate over each row in the original DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Add rows with quality = 1\n",
    "        for _ in range(row[f'{category_label.lower().replace(\" \", \"_\")}_counts']):\n",
    "            rows.append({\n",
    "                'country': row['country'],\n",
    "                'guild': row['guild'],\n",
    "                'century': row['century'],\n",
    "                'year': row['year'],\n",
    "                'depvar': 1\n",
    "            })\n",
    "        \n",
    "        # Add rows with quality = 0\n",
    "        for _ in range(row['sentence_count'] - row[f'{category_label.lower().replace(\" \", \"_\")}_counts']):\n",
    "            rows.append({\n",
    "                'country': row['country'],\n",
    "                'guild': row['guild'],\n",
    "                'century': row['century'],\n",
    "                'year': row['year'],\n",
    "                'depvar': 0\n",
    "            })\n",
    "    \n",
    "    # Create the new DataFrame from the list of rows\n",
    "    new_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Create dummy variables for 'mexico' and centuries\n",
    "    new_df['dummy_mexico'] = (new_df['country'] == 'mexico').astype(int)\n",
    "    new_df['dummy17'] = (new_df['century'] == 17).astype(int)\n",
    "    new_df['dummy18'] = (new_df['century'] == 18).astype(int)\n",
    "    \n",
    "    # Create interaction terms\n",
    "    new_df['mexico_x_17'] = new_df['dummy_mexico'] * new_df['dummy17']\n",
    "    new_df['mexico_x_18'] = new_df['dummy_mexico'] * new_df['dummy18']\n",
    "    \n",
    "    # Add the index column\n",
    "    new_df['index'] = range(1, len(new_df) + 1)\n",
    "    \n",
    "    # Convert the label to lowercase, replace spaces with underscores, and add the necessary suffix\n",
    "    # Rename the 'depvar' column to the category name\n",
    "    new_df = new_df.rename(columns={'depvar': category_label.lower().replace(\" \", \"_\")})\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels for categories. Order matters.\n",
    "labels = [\n",
    "    \"Entry Barriers\",\n",
    "    \"Human Capital\",\n",
    "    \"Product Quality\",\n",
    "    \"Markets\",\n",
    "    \"Enforcement\",\n",
    "    \"Religion\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Build datasets for each category and append them to the list\n",
    "for i, label in enumerate(labels):\n",
    "    category_df = build_dataset(df, str(i), label)\n",
    "    dfs.append(category_df)\n",
    "\n",
    "# Merge all dataframes on common columns ['country', 'guild', 'century', 'year', 'index']\n",
    "merged_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Remove duplicate columns (keeping the first occurrence)\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "\n",
    "# Specify the desired order of columns\n",
    "new_column_order = ['index', 'country', 'guild', 'century', 'year', 'entry_barriers', \n",
    "                    'human_capital', 'product_quality', 'markets', 'enforcement', \n",
    "                    'religion', 'other', 'dummy_mexico', 'dummy17', 'dummy18', \n",
    "                    'mexico_x_17', 'mexico_x_18']\n",
    "\n",
    "# Reorder the columns in merged_df\n",
    "merged_df = merged_df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save sentence-level_dataset under path: /Users/niclasgriesshaber/Desktop/guilds-llm/datasets/sentence_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save path\n",
    "save_path = os.path.normpath(os.path.join(current_directory, '..', 'datasets', 'sentence_dataset.csv'))\n",
    "print(f\"Save sentence-level_dataset under path: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to: /Users/niclasgriesshaber/Desktop/guilds-llm/datasets/sentence_dataset.csv\n",
      "Shape of the merged dataset: (1044, 17)\n",
      "Columns in the merged dataset:\n",
      "['index', 'country', 'guild', 'century', 'year', 'entry_barriers', 'human_capital', 'product_quality', 'markets', 'enforcement', 'religion', 'other', 'dummy_mexico', 'dummy17', 'dummy18', 'mexico_x_17', 'mexico_x_18']\n"
     ]
    }
   ],
   "source": [
    "# Save the merged dataset\n",
    "merged_df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Merged dataset saved to: {save_path}\")\n",
    "print(f\"Shape of the merged dataset: {merged_df.shape}\")\n",
    "print(\"Columns in the merged dataset:\")\n",
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guilds-nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
